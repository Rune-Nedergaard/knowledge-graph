{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ------------\n",
      "asttokens                     2.2.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "certifi                       2022.12.7\n",
      "charset-normalizer            3.1.0\n",
      "colorama                      0.4.6\n",
      "conllu                        4.5.2\n",
      "danlp                         0.1.2\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "executing                     1.2.0\n",
      "idna                          3.4\n",
      "importlib-metadata            6.0.0\n",
      "ipykernel                     6.15.0\n",
      "ipython                       8.11.0\n",
      "jedi                          0.18.2\n",
      "jupyter_client                8.0.3\n",
      "jupyter_core                  5.2.0\n",
      "matplotlib-inline             0.1.6\n",
      "nest-asyncio                  1.5.6\n",
      "numpy                         1.24.2\n",
      "oauthlib                      3.2.2\n",
      "packaging                     23.0\n",
      "pandas                        1.5.3\n",
      "parso                         0.8.3\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.0.1\n",
      "platformdirs                  3.1.1\n",
      "progressbar                   2.5\n",
      "prompt-toolkit                3.0.38\n",
      "psutil                        5.9.0\n",
      "pure-eval                     0.2.2\n",
      "pyconll                       3.1.0\n",
      "Pygments                      2.14.0\n",
      "python-dateutil               2.8.2\n",
      "pytz                          2022.7.1\n",
      "pywin32                       305.1\n",
      "pyzmq                         23.2.0\n",
      "requests                      2.28.2\n",
      "requests-oauthlib             1.3.1\n",
      "setuptools                    65.6.3\n",
      "six                           1.16.0\n",
      "stack-data                    0.6.2\n",
      "torch                         1.13.1+cu116\n",
      "torchaudio                    0.13.1+cu116\n",
      "torchvision                   0.14.1+cu116\n",
      "tornado                       6.2\n",
      "tqdm                          4.65.0\n",
      "traitlets                     5.9.0\n",
      "tweepy                        4.13.0\n",
      "typing_extensions             4.5.0\n",
      "urllib3                       1.26.15\n",
      "wcwidth                       0.2.6\n",
      "wheel                         0.38.4\n",
      "wincertstore                  0.2\n",
      "zipp                          3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdanlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_bert_ner_model\n\u001b[0;32m      2\u001b[0m bert \u001b[39m=\u001b[39m load_bert_ner_model()\n\u001b[0;32m      3\u001b[0m \u001b[39m# Get lists of tokens and labels in BIO format\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rune7\\anaconda3\\envs\\danlp\\lib\\site-packages\\danlp\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mspacy_models\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mflair_models\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbert_models\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rune7\\anaconda3\\envs\\danlp\\lib\\site-packages\\danlp\\models\\embeddings.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtempfile\u001b[39;00m \u001b[39mimport\u001b[39;00m TemporaryDirectory\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m sleep\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeyedvectors\u001b[39;00m \u001b[39mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdanlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownload\u001b[39;00m \u001b[39mimport\u001b[39;00m MODELS, download_model, DEFAULT_CACHE_DIR, \\\n\u001b[0;32m     31\u001b[0m     _unzip_process_func\n\u001b[0;32m     33\u001b[0m AVAILABLE_EMBEDDINGS \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwiki.da.wv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcc.da.wv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mconll17.da.wv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     34\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mnews.da.wv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msketchengine.da.wv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdslreddit.da.wv\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from danlp.models import load_bert_ner_model\n",
    "bert = load_bert_ner_model()\n",
    "# Get lists of tokens and labels in BIO format\n",
    "tokens, labels = bert.predict(\"Jens Peter Hansen kommer fra Danmark\")\n",
    "print(\" \".join([\"{}/{}\".format(tok,lbl) for tok,lbl in zip(tokens,labels)]))\n",
    "\n",
    "# To get a correct tokenization, you have to provide it yourself to BERT  by providing a list of tokens\n",
    "# (for example SpaCy can be used for tokenization)\n",
    "# With this option, output can also be choosen to be a dict with tags and position instead of BIO format\n",
    "tekst_tokenized = ['Han', 'hedder', 'Anders', 'And', 'Andersen', 'og', 'bor', 'i', 'Århus', 'C']\n",
    "bert.predict(tekst_tokenized, IOBformat=False)\n",
    "\"\"\"\n",
    "{'text': 'Han hedder Anders And Andersen og bor i Århus C',\n",
    " 'entities': [{'type': 'PER','text':'Anders And Andersen','start_pos': 11,'end_pos': 30},\n",
    "  {'type': 'LOC', 'text': 'Århus C', 'start_pos': 40, 'end_pos': 47}]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.datasets import Dacoref\n",
    "dacoref = Dacoref()\n",
    "# The corpus can be loaded with or without splitting into train, dev and test in a list in that order\n",
    "corpus = dacoref.load_as_conllu(predefined_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'danlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#from utils import print_speed_performance\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdanlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dacoref\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdanlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_xlmr_coref_model\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mallennlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleDataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'danlp'"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "#from utils import print_speed_performance\n",
    "\n",
    "from danlp.datasets import Dacoref\n",
    "from danlp.models import load_xlmr_coref_model\n",
    "\n",
    "from allennlp.data.data_loaders import SimpleDataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "# load the data\n",
    "dacoref = Dacoref()\n",
    "\n",
    "_, _, testset = dacoref.load_as_conllu(predefined_splits=True)\n",
    "\n",
    "num_sentences = len(testset)\n",
    "num_tokens = sum([len(s) for s in testset])\n",
    "\n",
    "def benchmark_xlmr_mdl():\n",
    "\n",
    "    from allennlp.data import DataLoader\n",
    "    from allennlp.training.util import evaluate\n",
    "\n",
    "    xlmr = load_xlmr_coref_model()\n",
    "    \n",
    "    instances = xlmr.dataset_reader.load_dataset(testset)\n",
    "    data_loader = SimpleDataLoader(instances, 1)\n",
    "    data_loader.index_with(xlmr.model.vocab)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metrics = evaluate(\n",
    "        xlmr.model,\n",
    "        data_loader\n",
    "    )\n",
    "\n",
    "    print('**XLM-R model**')\n",
    "    #print_speed_performance(start, num_sentences, num_tokens)\n",
    "    print('Precision : ', metrics['coref_precision'])\n",
    "    print('Recall : ', metrics['coref_recall'])\n",
    "    print('F1 : ', metrics['coref_f1'])\n",
    "    print('Mention Recall : ', metrics['mention_recall'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    benchmark_xlmr_mdl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Folketinget                         98\n",
       "Det Konservative Folkeparti         95\n",
       "Venstre, Danmarks Liberale Parti    94\n",
       "Udvalget for Forretningsordenen     94\n",
       "Socialdemokratiet                   94\n",
       "                                    ..\n",
       "Fanø Turist- og Erhvervsforening     1\n",
       "Søren Skov Knudsen, København K      1\n",
       "Torsten Mandal                       1\n",
       "Hans Jørgen Engbo, Nykøbing Sj       1\n",
       "Noah Sturis                          1\n",
       "Name: navn, Length: 14238, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aktør = pd.read_pickle('../data/raw/Aktør.pkl')\n",
    "Aktør['navn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
